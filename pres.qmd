---
# title: "Capacitación en R y herramientas de productividad"
# author: "Abril 2021"
format:
  revealjs:
    auto-stretch: false
    margin: 0
    slide-number: true
    scrollable: true
    preview-links: auto
    logo: imagenes/logo_portada2.png
    css: ine_quarto_styles.css
    # footer: <https://quarto.org>
---

#

<!---
# TODO: this does not work
 .linea-superior[]
.linea-inferior[] 
--->

<!---
# TODO: this does not work
 ![](imagenes/logo_portada2.png){.center style="width: 20%;"}   
--->

[]{.linea-superior} 
[]{.linea-inferior} 

<!---
 <img src="imagenes/logo_portada2.png" style="width: 20%"/>  
--->

<img src="imagenes/logo_portada2.png" width="20%"/>  

[**Penúltima (8va) sesión mentoría censo**]{.big-par .center-justified}

[**Proyecto Ciencia de Datos**]{.big-par .center-justified}

[**Enero 2024**]{.big-par .center-justified}


## Objetivos de la sesión

Resolver dudas respecto al trabajo realizado con el modelo de clasificación

. . .

Revisar recomendaciones para el etiquetado de datos

. . .

Revisar recomendaciones para la puesta en producción del modelo


# Comencemos con sus dudas

# Revisemos las recomendaciones


## Etiquetado de datos


Enfoque en la calidad

. . .

Priorizar calidad frente a cantidad

. . .

 
## Etiquetado de datos

Ocupación (oficio y tareas) y actividad económicas conforman una unidad

. . .

**Recomendación**: la selección de glosas únicas debiese considerar ambas variables  

. . .

La edición de las glosas es una decisión que puede afectar los resultados

. . .

<<<<<<< HEAD
**Recomendación**: etiquetar datos en estado bruto
=======
**Recomendación**: Etiquetar datos en estado bruto (edición debe realizarse en la etapa de entrenamiento)
>>>>>>> bd1a9de2282663c644d885589ce8fcc9499e5a6f


## Etiquetado de datos

Los clasificadores son complejos y tienen una curva de aprendizaje

. . .

**Recomendación**: descartar los códigos de las primeras semanas de trabajo y considerarlos como costo de aprendizaje

. . .

Monitoreo constante (diario o semanal) del desempeño de los codificadores en cuanto a cantidad y calidad

. . .

**Recomendación**: solicitar a Nomenclaturas auditorías mensuales 

**Recomendación**: el muestreo debería intentar que todos los codificadores estén bien representados

**Recomendación**: medir el progreso en cuanto a la coincidencia con Nomenclaturas


. . .

La retroalimentación hacia los codificadores puede tener un gran impacto

. . .

**Recomendación**: generar reportes y capacitaciones mensuales, abordando los problemas detectados por Nomenclaturas  

. . .


## Etiquetado de datos

No podemos alcanzar la calidad de las glosas que tiene una encuesta periódica

. . .

**Recomendación**: acordar criterios con Nomenclaturas respecto a la exigencia en cuanto a suficiencia de información

. . .

El proceso de revisión cruzada no asegura la ausencia de casos complejos

. . .

**Recomendación**: revisar glosas idénticas con distinto código

**Recomendación**: revisar algunos códigos complejos que se desprendan de las auditorías 

. . .

La distribución de registros y la entrega de cargas diferenciadas para cada codificador no es una tarea sencilla

. . .

**Recomendación**: Buscar un perfil con habilidades de programación

**Recomendación**: Evitar una excesiva diferenciación en las cargas



## Entrenamiento

La identificación de glosas con información insuficiente puede ser compleja

. . .

**Recomendación**: monitorear de cerca evolución de predicción de código 999. Actualmente contamos con
muy pocos datos para poder evaluarlo correctamente

**Recomendación**: algunas glosas podrían ser descartadas por heurísticas como número de carácteres. Sin embargo,
hay que tener cuidado, pues otras glosas podrían aportar la información necesaria para clasificar.

. . .

Quisiéramos poder corregir glosas mal escritas

**Recomendación**: en Python existen algunas librerías que permiten corregir errores ortográficos:  pyspellchecker, [Spanish spelling corrector](https://github.com/rcabg/Spanish-Spelling-Corrector), myspell, incluso GPT (a través de la API).

. . .

**[OJO]{.red}**: cualquier decisión de entrenamiento debe ser **siempre** contrastada contra el entrenamiento
anterior. Solo si esta nueva decisión trae mejoras en resultados, debiese ser incorporada.



## Puesta en producción {.medium-par}

A la hora de poner en producción el modelo es deseable, en general, que este sea fácil de
reproducir, compartir, auditar y ejecutar.

. . .

Para lograr esto, nuestra recomendación es utilizar Docker (reproducibilidad) y 
encapsular el trabajo en una API (facilidad para compartir y ejecutar). 

. . .

En términos de auditabilidad, el código en su forma actual ya es fácilmente auditable y 
el método propuesto solo encapsularía el código, sin introducir grandes dificultades.

. . .

Para lograr algo así, sería fundamental conseguir acceso a un **servidor** donde pudiera alojarse
la potencial API.

Para el desarrollo, las opciones son las siguientes:

- Pedir ayuda a TI para que les provea la infraestructura necesaria para esto (servidores, empaquetamiento).

- Nuestro equipo también puede ayudarles a empaquetar (desarrollo de API e infraestructura de código Docker).

- Pueden estudiar cómo su equipo podría hacerlo (por ejemplo, en R con `plumber`. Con Python preferimos `FastAPI`)


## Puesta en producción

**¿Qué logramos con esto?**

. . . 

Si utilizamos Docker, la aplicación correrá en cualquier computador o servidor, por lo que si es
necesario moverla de ubicación, el costo será muy bajo. Se hace cargo de la instalación del Sistema
Operativo, programas con Python o R, las librerías necesarias del proyecto y corre el código.

. . .

Si además creamos una API alojada en un servidor del INE, cualquier persona con acceso a este servidor podrá
correr el modelo, sin la necesidad de tener múltiples instalaciones, ni duplicar archivos grandes (como los _embeddings_, que pesan
más de 5GB)

. . .

**¿Cómo se ve en la práctica?**

[Probemos una API en producción en acción!](http://10.90.2.47:3123/docs)

## Puesta en producción {.small-par}

Nos gustaría ver algo así con respecto a las probabilidades obtenidas por el modelo.

:::: {layout-ncol=2}


::: fragment
![](imagenes/g1_cal_proba.png){width=10%}
:::

::: fragment

::: incremental
En este caso podemos ver que aproximadamente el 75% de las observaciones con mayor probabilidad máxima se puede calificar con una precisión superior al 90%


- Una estrategia podría ser codificar manualmente el 25% que tiene menores probabilidades máximas (más conservadora)

- Otra decisión podría ser seleccionar una probabilidad máxima de corte tal que, en promedio, se asegure que
el 90% de las observaciones vayan a ser bien codificadas por el modelo. (menos conservadora)
:::

:::

::::

#




<img src="imagenes/logo_portada2.png" width="20%"/>  

[**Penúltima (8va) sesión mentoría censo**]{.big-par .center-justified}

[**Proyecto Ciencia de Datos**]{.big-par .center-justified}

[**Enero 2024**]{.big-par .center-justified}


[]{.linea-superior} 
[]{.linea-inferior} 

